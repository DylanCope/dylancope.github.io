---
layout: page
title: About
permalink: /about/
---

I am a PhD student at King's College London and Imperial College London studying Computer Science in the [Safe and Trusted AI Centre for Doctoral Training](https://safeandtrustedai.org) (My profile can be found [here](https://safeandtrustedai.org/person/dylan-cope/)). My current work is into defining an information-theoretic measure of the “effectiveness” of explanations in a communicative multiagent setting. This involves setting up the problem of generating explanations as a two-player cooperative game in which rewards are given according to the effectiveness measure. As it’s a natural fit, I am working on using deep reinforcement learning to build agents that can play this game. My interest in explanatory AI is tied to my broader interests in scalable approaches to technical safety problems. More specifically, I expect that active learning approaches to the value alignment problem, such as reward modelling, would benefit from agents that are intrinsically motivated to explain their actions, motivations and reasoning faculties.

<div itemscope itemtype="https://schema.org/Person"><a itemprop="sameAs" content="https://orcid.org/0000-0003-1147-8010" href="https://orcid.org/0000-0003-1147-8010" target="orcid.widget" rel="me noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon">https://orcid.org/0000-0003-1147-8010</a></div>

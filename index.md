---
layout: page
title: Home
---

## PhD Research

I am a PhD student at King's College London and Imperial College London studying Computer Science in the [Safe and Trusted AI Centre for Doctoral Training](https://safeandtrustedai.org). Previously, I was a reserach intern at the [Center for Human-Compatible AI (CHAI)](humancompatible.ai). My doctoral research is about framing "explanation" in the context of *multi-agent communication* so as to explicitly take into account the recipient of the explanation (who we call the *explainee*). This research is inherently interdisciplinary; notably involving philosophy, social science, and cognitive science. 

The following cartoon shows a set-up of multi-agent reinforcement learning (MARL) with communication:

<p align="center">
<img src="./assets/marl_communication.png" width="400px" display="block" margin-left="auto" margin-right="auto" class="center"/>
</p>

## Other Interests

Outside of my PhD research I am broadly interested in language and cognitive science. This has led me to studying the exciting field of _emergent communication_ in reinforcement learning, and to studying inductive biases for deep learning systems that could facilitate more robust behaviour by having systems explicitly mimick cognitive functions such as analogy-making and information retrieval. 

## News

_June 6th, 2023:_ I will be at the CHAI Workshop on the 17th of June, 2023, presenting a poster on my work on applying Deep Reinforcement Learning to Tree Search, done in collaboration with Justin Svegliato and Stuart Russell.

_May 5, 2023:_ My paper ["Real-time Evolution of Multicellularity with Artificial Gene Regulation"](https://arxiv.org/abs/2305.12249) has been accepted to the [2023 Conference on Artificial Life](https://2023.alife.org/) for an oral presentation and publication in the proceedings. The conference will be hosted at Hokkaido University on July 24th to July 28th, 2023.

_May 4, 2023:_ Nandi Schoots presented our paper ["Low-Entropy Latent Variables Harm Out-of-Distribution Performance"](https://domaingen.github.io/accepted) at the International Conference on Learning Representations (ICLR) Domain Generalization Workshop. 

_September 22, 2022:_ I am helping a group of fellow London-based PhD students to organise the [Safe and Trustworthy AI Workshop](https://www.doc.ic.ac.uk/~chs219/stai-workshop/) on the 2nd of November, 2022, aimed at bringing together early-career researchers. Submit abstracts by the **28/09/2022**.

_April 13, 2022:_ I am excited to announce that I will be joining Stuart Russell's group the [Center for Human Compatible AI](https://humancompatible.ai/) at U.C. Berkeley this summer for a four month internship! I will be working with [Justin Svegliato](https://justinsvegliato.com/) on a project in "AI metareasoning".

_April 7, 2022:_ I have won a "Best Reviewer Award" for my work reviewing papers for [EmeCom@ICLR22](https://sites.google.com/view/emecom2022/home)! Thank you to the organisers for this recognition, and the gift of Fuji Sencha tea :)

_April 1, 2022:_ My paper ["Joining the Conversation: Towards Language Acquisition for Ad Hoc Team Play"](https://openreview.net/forum?id=SLqgf7ZCQbq) written with my PhD supervisor [Peter McBurney](https://nms.kcl.ac.uk/peter.mcburney/) has been accepted to the [the Emergent Communication Workshop at the International Conference on Learning Representations (EmeCom@ICLR22)](https://sites.google.com/view/emecom2022/home). I will lead a discussion group on the topic of the paper at the workshop.

_July 22, 2021:_ My team has won the Safe and Trusted AI Hackathon! We analysed stop-and-search data from the London metropolitan police in terms of disproportionality of stops for minority groups.

_March 27, 2021:_ My paper "A Measure of Explanatory Effectiveness" written with my PhD supervisor [Peter McBurney](https://nms.kcl.ac.uk/peter.mcburney/) has been accepted to the [1st International Workshop on Trusted Automated Decision-Making](https://3drationality.com/TADM2021/). I gave a talk at the workshop on the paper.

_Dec 31, 2020:_ My paper ["Learning to Communicate with Strangers via Channel Randomisation Methods"](https://drive.google.com/file/d/1FaBSE8jcuf6hGIbbp34Dxu7jPjh0iJl0/view?usp=sharing) written with [Nandi Schoots](https://safeandtrustedai.org/person/nandi-schoots/) was accepted to [the Emergent Communication Workshop at the Conference on Neural Information Processing Systems (EmeCom@NeurIPS2020)](https://sites.google.com/view/emecom2020/home). You can find the source code [on my GitHub](https://github.com/DylanCope/zero-shot-comm).

## Publications

Dylan Cope, 2023, [_Real-time Evolution of Multicellularity with Artificial Gene Regulation_](https://arxiv.org/abs/2305.12249), Proceedings of the 2023 Conference on Artificial Life (ALIFE23), MIT Press

Nandi Shoots, Dylan Cope, 2023, [_Low-Entropy Latent Variables Harm Out-of-Distribution Performance_](https://domaingen.github.io/accepted), International Conference on Learning Representations Domain Generalization Workshop (DomainGen@ICLR23)

Dylan Cope, Peter McBurney, 2022, [_Joining the Conversation: Towards Language Acquisition for Ad Hoc Team Play_](https://openreview.net/forum?id=SLqgf7ZCQbq), the 5th Emergent Communication Workshop at the International Conference on Learning Representations (EmeCom@ICLR22)

Dylan Cope, Peter McBurney, 2021, _A Measure of Explanatory Effectiveness_, 1st International Workshop on Trusted Automated Decision-Making

Dylan Cope, Nandi Schoots, 2020, [_Learning to Communicate with Strangers via Channel Randomisation Methods_](https://drive.google.com/file/d/1FaBSE8jcuf6hGIbbp34Dxu7jPjh0iJl0/view?usp=sharing), 4th NeurIPS Workshop on Emergent Communication

## Teaching

2021/22:

* 6CCS3ML - Machine Learning GTA

2022/23:

* 6CCS3ML - Machine Learning GTA

---

<div itemscope itemtype="https://schema.org/Person"><a itemprop="sameAs" content="https://orcid.org/0000-0003-1147-8010" href="https://orcid.org/0000-0003-1147-8010" target="orcid.widget" rel="me noopener noreferrer" style="vertical-align:top;"><img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" alt="ORCID iD icon">https://orcid.org/0000-0003-1147-8010</a></div>

[KCL Pure Research Profile](https://kclpure.kcl.ac.uk/portal/en/persons/dylan-cope)
